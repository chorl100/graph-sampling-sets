{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da727e8c",
   "metadata": {},
   "source": [
    "# Deep Detractor Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3729af57",
   "metadata": {},
   "source": [
    "Solve the binary classification problem of deciding whether a customer is a deep detractor. \n",
    "A deep detractor is someone who replied with a recommendation score of 2 or less in an NPS survey.\n",
    "\n",
    "We work on a ground truth graph, i.e. a signal was observed for all nodes. \n",
    "We sample a small subset of the observed signal and try to reconstruct the signal on the entire graph.\n",
    "Then we compute precision-recall curves with the reconstructed signal.\n",
    "\n",
    "We consider the performance for increasing sample size.\n",
    "The execution for a single sample size can be done with `deep_detractor_detection.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38881d24",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15dd8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "PROJECT_PATH = \"/home/christopher_orlowicz1_vodafone_c/gershgorin\"\n",
    "sys.path.append(PROJECT_PATH)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12a8e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $PROJECT_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab3d8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -q -r requirements.txt\n",
    "#!pip install --force-reinstall faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3efa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from google.cloud import bigquery\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_gbq\n",
    "import scipy\n",
    "from scipy import sparse\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "import src.utils.plotting as plt_util\n",
    "from src.gershgorin.bs_gda import bs_gda\n",
    "from src.graph.graph import Graph\n",
    "from src.gsp import reconstruction\n",
    "from src.utils import data_handler\n",
    "from src.utils.yaml_reader import YamlReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e633866",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5005f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify directory from which to load the data\n",
    "DIR = \"out/customer_analytics/2023-01\"\n",
    "size = \"1000\"\n",
    "# load graph\n",
    "adj_matrix = sparse.load_npz(f\"{DIR}/graph/knn/{size}/adj_matrix.npz\")\n",
    "graph = Graph(adj_matrix)\n",
    "# load signal\n",
    "s = np.load(f\"{DIR}/signal/{size}/nps.npy\").flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6b8397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling configuration\n",
    "sampling_budgets = np.linspace(100, 900, 9).astype(int)\n",
    "config = {\n",
    "      \"mu\": 0.01,  # regularization strength of smoothness prior\n",
    "      \"eps\": 1e-5,  # precision\n",
    "      \"p_hops\": 3,  # number of hops to take in the node neighborhood\n",
    "      \"parallel\": True  # whether to parallelize the algorithm where possible\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550cb4c5",
   "metadata": {},
   "source": [
    "## Run classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d9451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_deep_detractor(s: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Checks which customers are deep detractors.\n",
    "    A deep detractor is defined as someone who gave a recommendation score <= 2.\n",
    "    :param s: NPS signal vector\n",
    "    :return: boolean array\n",
    "    \"\"\"\n",
    "    return s <= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49887cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall_curve(precision_vals: np.ndarray, recall_vals: np.ndarray, label: str):\n",
    "    \"\"\"\n",
    "    Draws a precision-recall curve.\n",
    "    :param precision_vals: Precision values such that element i is the precision of predictions with score >= thresholds[i] and the last element is 1.\n",
    "    :param recall_vals: Decreasing recall values such that element i is the recall of predictions with score >= thresholds[i] and the last element is 0.\n",
    "    :param label: label of the curve\n",
    "    \"\"\"\n",
    "    plt.plot(recall_vals, precision_vals, label=k)\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e950d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "plt.title(\"Precision-recall curve\\nfor the detection of deep detractors\")\n",
    "\n",
    "reconstructions = list()\n",
    "for k in tqdm(sampling_budgets):\n",
    "    print(\"Selecting sampling set...\")\n",
    "    sampling_set, _ = bs_gda(graph, k, **config)\n",
    "    \n",
    "    print(\"Reconstructing signal...\")\n",
    "    s_rec = reconstruction.reconstruct_signal(graph.laplacian(), sampling_set, s[sampling_set])\n",
    "    reconstructions.append(s_rec)\n",
    "    \n",
    "    print(\"Detecting deep detractors...\")\n",
    "    y_true = is_deep_detractor(s)\n",
    "    # invert score to stick to scikit-learn convention which uses y_score >= thresh instead of y_score <= thresh\n",
    "    y_score = 1 / (s_rec + 1e-8)\n",
    "    precision_vals, recall_vals, thresholds = metrics.precision_recall_curve(y_true, y_score, pos_label=1)\n",
    "    plot_precision_recall_curve(precision_vals, recall_vals, label=f\"{k}\")\n",
    "    \n",
    "plt.legend(title=\"Sample size $k$\", loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.savefig(\"out/dd_detection_increasing_sample_size.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7f6593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
